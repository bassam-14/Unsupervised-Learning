{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16046619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6414ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Preprocess Data\n",
    "df = df.drop(columns=[\"id\", \"Unnamed: 32\"])\n",
    "X_df = df.drop(columns=[\"diagnosis\"])\n",
    "y_df = df[\"diagnosis\"]\n",
    "\n",
    "# Convert to numpy\n",
    "X = X_df.to_numpy()\n",
    "y = y_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, k_components, covariance_type='full'):\n",
    "        self.k_components = k_components\n",
    "        self.covariance_type = covariance_type\n",
    "\n",
    "        self.means = None\n",
    "        self.covariances = None\n",
    "        self.weights = None\n",
    "        self.responsibilities = None\n",
    "\n",
    "        # Attributes for Experiments\n",
    "        self.log_likelihoods = []\n",
    "        self.aic = None\n",
    "        self.bic = None\n",
    "        self.labels = None\n",
    "\n",
    "    def fit(self, X, max_iter=100, tol=1e-6):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.initialize_parameters(X)\n",
    "\n",
    "        log_likelihood_old = None\n",
    "\n",
    "        for iteration in range(max_iter):\n",
    "            # E-step\n",
    "            self.responsibilities = self.e_step(X)\n",
    "\n",
    "            # M-step\n",
    "            self.m_step(X)\n",
    "\n",
    "            # Compute log likelihood\n",
    "            log_likelihood_new = self.compute_log_likelihood(X)\n",
    "            self.log_likelihoods.append(log_likelihood_new)\n",
    "\n",
    "            # Check for convergence\n",
    "            if log_likelihood_old is not None and abs(log_likelihood_new - log_likelihood_old) < tol:\n",
    "                break\n",
    "            log_likelihood_old = log_likelihood_new\n",
    "\n",
    "        # Compute AIC and BIC\n",
    "        self.compute_aic_bic(X)\n",
    "\n",
    "        # Assign labels based on responsibilities\n",
    "        self.labels = np.argmax(self.responsibilities, axis=1)\n",
    "\n",
    "    def initialize_parameters(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        random_indices = np.random.choice(n_samples, self.k_components, replace=False)\n",
    "        self.means = X[random_indices]\n",
    "\n",
    "        self.weights = np.ones(self.k_components) / self.k_components\n",
    "        global_cov = np.cov(X, rowvar=False)\n",
    "\n",
    "        if self.covariance_type == 'full':\n",
    "            self.covariances = np.array([global_cov for _ in range(self.k_components)])\n",
    "        elif self.covariance_type == 'tied':\n",
    "            self.covariances = global_cov\n",
    "        elif self.covariance_type == 'diag':\n",
    "            diag = np.diag(global_cov)\n",
    "            self.covariances = np.array([diag for _ in range(self.k_components)])\n",
    "        elif self.covariance_type == 'spherical':\n",
    "            var = np.mean(np.diag(global_cov))\n",
    "            self.covariances = np.array([var for _ in range(self.k_components)])\n",
    "    \n",
    "    def e_step(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        log_numerators = np.zeros((n_samples, self.k_components))\n",
    "\n",
    "        for k in range(self.k_components):\n",
    "            if self.covariance_type == 'full':\n",
    "                cov_k = self.covariances[k]\n",
    "            elif self.covariance_type == 'tied':\n",
    "                cov_k = self.covariances\n",
    "            elif self.covariance_type == 'diag':\n",
    "                cov_k = self.covariances[k]\n",
    "            elif self.covariance_type == 'spherical':\n",
    "                cov_k = self.covariances[k]\n",
    "            \n",
    "            log_likelihood = self.log_gaussian(X, k, cov_k)\n",
    "            log_numerators[:, k] = np.log(self.weights[k] + 1e-10) + log_likelihood\n",
    "\n",
    "        a_max = np.max(log_numerators, axis=1, keepdims=True)\n",
    "        shifted_numerators = log_numerators - a_max\n",
    "        numerators = np.exp(shifted_numerators)\n",
    "\n",
    "        denominator = np.sum (numerators, axis=1, keepdims=True)\n",
    "        responsibilities = numerators / denominator\n",
    "\n",
    "        return responsibilities \n",
    "        \n",
    "    def log_gaussian(self, X, k, cov):\n",
    "        mean = self.means[k]\n",
    "        _, n_features = X.shape\n",
    "\n",
    "        if self.covariance_type in ['spherical', 'diag']:\n",
    "            cov_stable = cov + 1e-6\n",
    "\n",
    "            if self.covariance_type == 'spherical':\n",
    "                log_det = n_features * np.log(cov_stable)\n",
    "                inverse = 1.0 / cov_stable\n",
    "            else:\n",
    "                log_det = np.sum(np.log(cov_stable))\n",
    "                inverse = 1.0 / cov_stable\n",
    "\n",
    "            diff = X - mean\n",
    "            quadratic_term = np.sum ((diff**2) * inverse, axis = 1)\n",
    "        \n",
    "        else:\n",
    "            cov_stable = cov + np.eye(n_features) * 1e-6\n",
    "\n",
    "            _, log_det = np.linalg.slogdet(cov_stable)\n",
    "            inverse = np.linalg.inv(cov_stable)\n",
    "\n",
    "            diff = X - mean\n",
    "            quadratic_term = np.sum(np.dot(diff, inverse)*diff, axis=1)\n",
    "        \n",
    "        constant = -0.5 * n_features * np.log(2*np.pi)\n",
    "        return constant - 0.5 * log_det - 0.5 * quadratic_term\n",
    "    \n",
    "    def m_step (self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Update Weights (PI)\n",
    "        sum_res = np.sum(self.responsibilities, axis=0)\n",
    "        self.weights = sum_res / n_samples\n",
    "\n",
    "        # Update Means\n",
    "        self.means = np.dot(self.responsibilities.T, X) / sum_res.reshape(-1, 1)\n",
    "\n",
    "        # Update Covariances\n",
    "        if self.covariance_type == 'full':\n",
    "            self.covariances = np.zeros((self.k_components, n_features, n_features))\n",
    "            for k in range(self.k_components):\n",
    "                diff = X - self.means[k]\n",
    "                weighted_diff = self.responsibilities[:, k].reshape(-1, 1) * diff\n",
    "                self.covariances[k] = np.dot(weighted_diff.T, diff) / sum_res[k]\n",
    "                self.covariances[k].flat[::n_features + 1] += 1e-6\n",
    "        \n",
    "        elif self.covariance_type == 'tied':\n",
    "            cov = np.zeros((n_features, n_features))\n",
    "            for k in range(self.k_components):\n",
    "                diff = X - self.means[k]\n",
    "                weighted_diff = self.responsibilities[:, k].reshape(-1, 1) * diff\n",
    "                cov += np.dot(weighted_diff.T, diff)\n",
    "            self.covariances = cov / n_samples\n",
    "            self.covariances.flat[::n_features + 1] += 1e-6\n",
    "        \n",
    "        elif self.covariance_type == 'diag':\n",
    "            self.covariances = np.zeros((self.k_components, n_features))\n",
    "            for k in range(self.k_components):\n",
    "                diff = X - self.means[k]\n",
    "                weighted_diff_sq = self.responsibilities[:, k].reshape(-1, 1) * (diff ** 2)\n",
    "                self.covariances[k] = np.sum(weighted_diff_sq, axis=0) / sum_res[k] + 1e-6\n",
    "        \n",
    "        elif self.covariance_type == 'spherical':\n",
    "            self.covariances = np.zeros(self.k_components)\n",
    "            for k in range(self.k_components):\n",
    "                diff = X - self.means[k]\n",
    "                weighted_diff_sq = self.responsibilities[:, k].reshape(-1, 1) * (diff ** 2)\n",
    "                self.covariances[k] = np.sum(weighted_diff_sq) / (n_features * sum_res[k]) + 1e-6\n",
    "\n",
    "    def compute_log_likelihood(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        log_numerators = np.zeros((n_samples, self.k_components))\n",
    "\n",
    "        for k in range(self.k_components):\n",
    "            if self.covariance_type == 'full':\n",
    "                cov_k = self.covariances[k]\n",
    "            elif self.covariance_type == 'tied':\n",
    "                cov_k = self.covariances\n",
    "            elif self.covariance_type == 'diag':\n",
    "                cov_k = self.covariances[k]\n",
    "            elif self.covariance_type == 'spherical':\n",
    "                cov_k = self.covariances[k]\n",
    "            \n",
    "            # Compute log-probability for component k\n",
    "            log_density = self.log_gaussian(X, k, cov_k)\n",
    "            log_numerators[:, k] = np.log(self.weights[k] + 1e-10) + log_density\n",
    "\n",
    "        a_max = np.max(log_numerators, axis=1, keepdims=True)\n",
    "        return np.sum(a_max + np.log(np.sum(np.exp(log_numerators - a_max), axis=1)))\n",
    "    \n",
    "    def compute_aic_bic(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        log_likelihood = self.log_likelihoods[-1]\n",
    "\n",
    "        n_params = 0\n",
    "        # Means parameters (K * D)\n",
    "        n_params += self.k_components * n_features\n",
    "        \n",
    "        # Weights parameters (K - 1)\n",
    "        n_params += self.k_components - 1\n",
    "\n",
    "        # Covariance parameters\n",
    "        if self.covariance_type == 'full':\n",
    "            # K * (D * (D+1) / 2)\n",
    "            n_params += self.k_components * n_features * (n_features + 1) // 2\n",
    "        elif self.covariance_type == 'tied':\n",
    "            # 1 shared matrix: D * (D+1) / 2\n",
    "            n_params += n_features * (n_features + 1) // 2\n",
    "        elif self.covariance_type == 'diag':\n",
    "            # K * D\n",
    "            n_params += self.k_components * n_features\n",
    "        elif self.covariance_type == 'spherical':\n",
    "            # K\n",
    "            n_params += self.k_components\n",
    "\n",
    "        # Compute AIC and BIC\n",
    "        self.aic = 2 * n_params - 2 * log_likelihood\n",
    "        self.bic = n_params * np.log(n_samples) - 2 * log_likelihood\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
